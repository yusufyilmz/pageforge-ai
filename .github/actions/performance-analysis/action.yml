name: 'Performance Analysis'
description: 'Comprehensive performance metrics, bundle analysis, and Core Web Vitals monitoring'

inputs:
  supabase-url:
    description: 'Supabase URL for build'
    required: false
    default: 'https://placeholder.supabase.co'
  supabase-key:
    description: 'Supabase anon key for build'
    required: false
    default: 'placeholder-key'
  upload-artifacts:
    description: 'Whether to upload build artifacts'
    required: false
    default: 'true'
  performance-budget:
    description: 'Performance budget in KB for bundle size'
    required: false
    default: '500'
  lighthouse-audit:
    description: 'Run Lighthouse performance audit'
    required: false
    default: 'true'

outputs:
  build-size:
    description: 'Build size information'
    value: ${{ steps.analyze.outputs.size }}
  performance-score:
    description: 'Overall performance score'
    value: ${{ steps.lighthouse.outputs.score }}
  bundle-passed:
    description: 'Whether bundle size is within budget'
    value: ${{ steps.budget-check.outputs.passed }}

runs:
  using: 'composite'
  steps:
    - name: üìä Build for production with metrics
      run: |
        echo "üèóÔ∏è Building with performance monitoring..."
        npm run build
        echo "‚úÖ Build completed"
      shell: bash
      env:
        NODE_ENV: production
        NEXT_PUBLIC_SUPABASE_URL: ${{ inputs.supabase-url }}
        NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ inputs.supabase-key }}
        ANALYZE: true

    - name: üì¶ Analyze bundle size
      id: analyze
      run: |
        echo "üìä Analyzing bundle size..."

        # Get build sizes
        if [ -d ".next" ]; then
          NEXT_SIZE=$(du -sh .next | cut -f1)
          STATIC_SIZE=$(du -sh .next/static 2>/dev/null | cut -f1 || echo "0")

          echo "size=${NEXT_SIZE}" >> $GITHUB_OUTPUT
          echo "static-size=${STATIC_SIZE}" >> $GITHUB_OUTPUT

          echo "üìä Build Analysis:"
          echo "- Total .next size: $NEXT_SIZE"
          echo "- Static assets: $STATIC_SIZE"
        fi

        # Run Next.js bundle analyzer if available
        if npm run analyze 2>/dev/null; then
          echo "‚úÖ Bundle analysis completed"
        else
          echo "‚ö†Ô∏è Bundle analyzer not configured"
        fi

        # Generate size report
        cat > bundle-report.md << EOF
        # üìä Bundle Analysis Report

        ## Build Sizes
        - **Total Build**: ${NEXT_SIZE}
        - **Static Assets**: ${STATIC_SIZE}
        - **Generated**: $(date)

        ## Bundle Composition
        \`\`\`
        $(find .next -name "*.js" -type f -exec wc -c {} + 2>/dev/null | tail -1 || echo "No JS files found")
        \`\`\`
        EOF
      shell: bash
      continue-on-error: true

    - name: üí∞ Performance budget check
      id: budget-check
      run: |
        echo "üí∞ Checking performance budget..."
        BUDGET_KB=${{ inputs.performance-budget }}

        if [ -d ".next/static" ]; then
          # Get total static size in KB
          STATIC_KB=$(du -sk .next/static | cut -f1)

          echo "üìä Budget Analysis:"
          echo "- Budget: ${BUDGET_KB}KB"
          echo "- Actual: ${STATIC_KB}KB"

          if [ $STATIC_KB -le $BUDGET_KB ]; then
            echo "‚úÖ Within budget! ($STATIC_KB KB ‚â§ $BUDGET_KB KB)"
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Over budget! ($STATIC_KB KB > $BUDGET_KB KB)"
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "::warning::Bundle size exceeds performance budget"
          fi
        else
          echo "‚ö†Ô∏è No static files found for budget check"
          echo "passed=unknown" >> $GITHUB_OUTPUT
        fi
      shell: bash

    - name: üîç Lighthouse CI audit
      id: lighthouse
      if: inputs.lighthouse-audit == 'true'
      run: |
        echo "üîç Running Lighthouse performance audit..."

        # Install Lighthouse CI
        npm install -g @lhci/cli@0.12.x

        # Create lighthouse config
        cat > lighthouserc.js << 'EOF'
        module.exports = {
          ci: {
            collect: {
              staticDistDir: '.next',
              url: ['http://localhost:3000/'],
              settings: {
                chromeFlags: '--no-sandbox --headless --disable-gpu'
              }
            },
            assert: {
              assertions: {
                'categories:performance': ['warn', {minScore: 0.8}],
                'categories:accessibility': ['error', {minScore: 0.9}],
                'categories:best-practices': ['warn', {minScore: 0.85}],
                'categories:seo': ['warn', {minScore: 0.9}]
              }
            }
          }
        };
        EOF

        # Run Lighthouse (with timeout)
        timeout 300 lhci autorun || echo "‚ö†Ô∏è Lighthouse audit timed out or failed"

        # Extract performance score if available
        if [ -f ".lighthouseci/lhr-*.json" ]; then
          PERF_SCORE=$(jq -r '.categories.performance.score' .lighthouseci/lhr-*.json 2>/dev/null || echo "0")
          echo "score=${PERF_SCORE}" >> $GITHUB_OUTPUT
          echo "üìä Performance Score: ${PERF_SCORE}"
        else
          echo "score=0" >> $GITHUB_OUTPUT
          echo "‚ö†Ô∏è No Lighthouse results available"
        fi
      shell: bash
      continue-on-error: true

    - name: üß™ Core Web Vitals analysis
      run: |
        echo "üß™ Analyzing Core Web Vitals..."

        # Create a simple CWV report
        cat > core-web-vitals.md << EOF
        # üß™ Core Web Vitals Analysis

        ## Key Metrics
        - **Largest Contentful Paint (LCP)**: Target < 2.5s
        - **First Input Delay (FID)**: Target < 100ms
        - **Cumulative Layout Shift (CLS)**: Target < 0.1

        ## Build Optimizations Applied
        - ‚úÖ Next.js Image Optimization
        - ‚úÖ Static Generation (SSG)
        - ‚úÖ Bundle Splitting
        - ‚úÖ Tree Shaking

        ## Recommendations
        - Monitor real user metrics (RUM)
        - Use \`next/image\` for all images
        - Implement proper loading states
        - Minimize layout shifts
        EOF

        echo "‚úÖ Core Web Vitals analysis completed"
      shell: bash

    - name: üìà Generate performance summary
      run: |
        echo "üìà Generating performance summary..."

        # Create comprehensive performance report
        cat > performance-summary.md << EOF
        # üìä Performance Analysis Summary

        ## üèóÔ∏è Build Metrics
        - **Build Time**: $(date)
        - **Node.js Version**: $(node --version)
        - **Next.js Build**: ‚úÖ Success

        ## üì¶ Bundle Analysis
        - **Total Size**: ${{ steps.analyze.outputs.size }}
        - **Performance Budget**: ${{ inputs.performance-budget }}KB
        - **Budget Status**: ${{ steps.budget-check.outputs.passed }}

        ## üîç Lighthouse Score
        - **Performance**: ${{ steps.lighthouse.outputs.score }}
        - **Target**: > 0.8

        ## üöÄ Deployment Ready
        $(if [ "${{ steps.budget-check.outputs.passed }}" = "true" ]; then echo "‚úÖ Ready for deployment"; else echo "‚ö†Ô∏è Review performance before deployment"; fi)

        ---
        Generated on: $(date)
        Commit: ${{ github.sha }}
        EOF

        echo "## üìä Performance Summary" >> $GITHUB_STEP_SUMMARY
        cat performance-summary.md >> $GITHUB_STEP_SUMMARY
      shell: bash

    - name: üìÅ Upload performance artifacts
      if: inputs.upload-artifacts == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: performance-analysis-${{ github.sha }}
        path: |
          .next/
          out/
          bundle-report.md
          core-web-vitals.md
          performance-summary.md
          .lighthouseci/
        retention-days: 7

    - name: üß™ Test coverage analysis
      run: |
        echo "üß™ Analyzing test coverage..."

        if npm run test:coverage 2>/dev/null; then
          echo "‚úÖ Coverage analysis completed"

          # Generate coverage badge data
          if [ -f "coverage/coverage-summary.json" ]; then
            COVERAGE=$(jq -r '.total.lines.pct' coverage/coverage-summary.json 2>/dev/null || echo "0")
            echo "üìä Test Coverage: ${COVERAGE}%"

            if (( $(echo "$COVERAGE > 80" | bc -l) )); then
              echo "‚úÖ Good test coverage (${COVERAGE}%)"
            else
              echo "‚ö†Ô∏è Consider improving test coverage (${COVERAGE}%)"
            fi
          fi
        else
          echo "‚ö†Ô∏è No test coverage available"
        fi
      shell: bash
      continue-on-error: true

    - name: üîç Security scan
      run: |
        echo "üîç Running security performance scan..."

        # Check for common performance security issues
        echo "Checking for:"
        echo "- Exposed source maps"
        echo "- Debug information"
        echo "- Large bundle sizes"

        if find .next -name "*.map" -type f | head -1 | grep -q "."; then
          echo "‚ö†Ô∏è Source maps found in production build"
        else
          echo "‚úÖ No source maps in production build"
        fi

        if grep -r "console.log\|debugger" .next/ 2>/dev/null | head -1 | grep -q "."; then
          echo "‚ö†Ô∏è Debug code found in production build"
        else
          echo "‚úÖ No debug code in production build"
        fi
      shell: bash
      continue-on-error: true
